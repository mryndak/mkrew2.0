# Cloud Build configuration for ML service deployment to Cloud Run
# This pipeline builds ML service Docker image and deploys to Cloud Run with authentication

steps:
  # Step 1: Build ML service Docker image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-ml-image'
    args:
      - 'build'
      - '-t'
      - 'gcr.io/$PROJECT_ID/mkrew-ml:$BUILD_ID'
      - '-t'
      - 'gcr.io/$PROJECT_ID/mkrew-ml:latest'
      - '-f'
      - 'ml/Dockerfile'
      - 'ml/'

  # Step 2: Push image to Container Registry
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-ml-image'
    args:
      - 'push'
      - 'gcr.io/$PROJECT_ID/mkrew-ml:$BUILD_ID'
    waitFor: ['build-ml-image']

  # Step 3: Deploy to Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'deploy-to-cloud-run'
    entrypoint: 'gcloud'
    args:
      - 'run'
      - 'deploy'
      - 'mkrew-ml-${_ENVIRONMENT}'
      - '--image'
      - 'gcr.io/$PROJECT_ID/mkrew-ml:$BUILD_ID'
      - '--region'
      - '${_REGION}'
      - '--platform'
      - 'managed'
      - '--no-allow-unauthenticated'  # Require authentication
      - '--service-account'
      - 'mkrew-ml-sa@$PROJECT_ID.iam.gserviceaccount.com'
      - '--set-env-vars'
      - 'PORT=8080,FLASK_ENV=production,DEBUG=False'
      - '--set-secrets'
      - 'ML_API_KEY=mkrew-ml-api-key:latest'
      - '--memory'
      - '${_MEMORY}'
      - '--cpu'
      - '${_CPU}'
      - '--timeout'
      - '300s'
      - '--max-instances'
      - '${_MAX_INSTANCES}'
      - '--min-instances'
      - '${_MIN_INSTANCES}'
      - '--concurrency'
      - '80'
      - '--ingress'
      - 'internal-and-cloud-load-balancing'  # Only accessible from VPC and load balancer
    waitFor: ['push-ml-image']
    secretEnv: []

  # Step 4: Grant backend service account permission to invoke ML service
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'grant-backend-access'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        gcloud run services add-iam-policy-binding mkrew-ml-${_ENVIRONMENT} \
          --region=${_REGION} \
          --member="serviceAccount:mkrew-backend-sa@$PROJECT_ID.iam.gserviceaccount.com" \
          --role="roles/run.invoker"
    waitFor: ['deploy-to-cloud-run']

  # Step 5: Get and display service URL
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'get-service-url'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        SERVICE_URL=$(gcloud run services describe mkrew-ml-${_ENVIRONMENT} \
          --region=${_REGION} \
          --format='value(status.url)')
        echo "ML Service deployed at: $SERVICE_URL"
        echo "$SERVICE_URL" > /workspace/ml-service-url.txt
    waitFor: ['grant-backend-access']

  # Step 6: Test health endpoint (should work without auth)
  - name: 'gcr.io/cloud-builders/curl'
    id: 'test-health-endpoint'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        SERVICE_URL=$(cat /workspace/ml-service-url.txt)
        echo "Testing health endpoint: $SERVICE_URL/health"
        curl -f "$SERVICE_URL/health" || exit 1
    waitFor: ['get-service-url']

  # Step 7: Push latest tag
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-latest-tag'
    args:
      - 'push'
      - 'gcr.io/$PROJECT_ID/mkrew-ml:latest'
    waitFor: ['test-health-endpoint']

# Store images in Container Registry
images:
  - 'gcr.io/$PROJECT_ID/mkrew-ml:$BUILD_ID'
  - 'gcr.io/$PROJECT_ID/mkrew-ml:latest'

# Substitution variables
substitutions:
  _ENVIRONMENT: 'dev'  # dev, staging, prod
  _REGION: 'europe-central2'
  _MEMORY: '2Gi'  # ML models need more memory
  _CPU: '2'
  _MAX_INSTANCES: '10'
  _MIN_INSTANCES: '1'  # Keep 1 instance warm for faster response

options:
  machineType: 'E2_HIGHCPU_8'
  logging: CLOUD_LOGGING_ONLY

timeout: '1800s'  # 30 minutes (TensorFlow installation takes time)
